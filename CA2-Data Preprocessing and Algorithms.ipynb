{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Tutorial\n",
    "    Author:    Theodora Tataru\n",
    "               C00231174\n",
    "    Tutor:     Greg Doyle\n",
    "    Course:    Software Development, 4th year\n",
    "    Institute: Institute of Technology Carlow\n",
    "    Year:      2020\n",
    "\n",
    "### This is tutorial focuses on various preprocessing data techniques and algorithms\n",
    "#### Pre-processing data methods:\n",
    "    - cleaning data\n",
    "    - data inegration\n",
    "    - data reduction\n",
    "\n",
    "#### Algorithms:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "This tutorial demonstrates different techniques for pre-processing data.\n",
    "In this part of the tutorial, the following pre-processing methods:\n",
    "    - data cleaning\n",
    "        - handle missing data\n",
    "        - handle noisy data\n",
    "        - binning data for data smoothing\n",
    "    - data integration and transformation\n",
    "        - handle duplicate data\n",
    "        - data integration\n",
    "    - data reduction\n",
    "        - cube aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning - Missing data\n",
    "\n",
    "### Packages needed:\n",
    "    - Python 3\n",
    "    - Pandas\n",
    "    - NumPy\n",
    "    - Scikit-Learn\n",
    "### Overview\n",
    "#### Dataset: Diabetes dataset\n",
    "    - Diabetes Dataset\n",
    "    - Has missing values: YES\n",
    "    - Source: National Institute of Diabetes and Digestive Kidney Diseases\n",
    "    - Date: 1990\n",
    "    - Number of instances: 768\n",
    "    - Number of attributes: 8+\n",
    "           1. Number of times pregnant\n",
    "           2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "           3. Diastolic blood pressure (mm Hg)\n",
    "           4. Triceps skinfold thickness (mm)\n",
    "           5. 2-Hour serum insulin (mu U/ml)\n",
    "           6. Body mass index (weight in kg/(height in m)^2)\n",
    "           7. Diabetes pedigree function\n",
    "           8. Age (years)\n",
    "           9. Class variable (0 or 1)\n",
    "#### Process:\n",
    "    - mark missing values\n",
    "    - remove rows with missing values\n",
    "    - replace missing values\n",
    "    - use algorithms that support missing values\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6  148  72  35    0  33.6  0.627  50  1\n",
      "0     1   85  66  29    0  26.6  0.351  31  0\n",
      "1     8  183  64   0    0  23.3  0.672  32  1\n",
      "2     1   89  66  23   94  28.1  0.167  21  0\n",
      "3     0  137  40  35  168  43.1  2.288  33  1\n",
      "4     5  116  74   0    0  25.6  0.201  30  0\n",
      "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
      "762  10  101  76  48  180  32.9  0.171  63  0\n",
      "763   2  122  70  27    0  36.8  0.340  27  0\n",
      "764   5  121  72  23  112  26.2  0.245  30  0\n",
      "765   1  126  60   0    0  30.1  0.349  47  1\n",
      "766   1   93  70  31    0  30.4  0.315  23  0\n",
      "\n",
      "[767 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "## Mark Missing values\n",
    "from pandas import read_csv ## used to load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv') ## load the data set from harddisk\n",
    "print(dataset) ## print the summary of the dataset, to see missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data can be represented by out-of-range values. In a numeric field where values should be positive, missing data can be represented by 0 or negative numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                6         148          72          35           0        33.6  \\\n",
      "count  767.000000  767.000000  767.000000  767.000000  767.000000  767.000000   \n",
      "mean     3.842243  120.859192   69.101695   20.517601   79.903520   31.990482   \n",
      "std      3.370877   31.978468   19.368155   15.954059  115.283105    7.889091   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
      "50%      3.000000  117.000000   72.000000   23.000000   32.000000   32.000000   \n",
      "75%      6.000000  140.000000   80.000000   32.000000  127.500000   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "            0.627          50           1  \n",
      "count  767.000000  767.000000  767.000000  \n",
      "mean     0.471674   33.219035    0.348110  \n",
      "std      0.331497   11.752296    0.476682  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243500   24.000000    0.000000  \n",
      "50%      0.371000   29.000000    0.000000  \n",
      "75%      0.625000   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "## usingPanda DataFrame, we can print the dataset summary statistics on each field\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the above line, there are fields that have a minimum value of zero. On some columns, the value of zero does not make sense and indicates that their values are missing.\n",
    "\n",
    "Columns with missing values:\n",
    "\n",
    "    1: Plasma glucose concentration\n",
    "    2: Diastolic blood pressure\n",
    "    3: Triceps skinfold thickness\n",
    "    4: 2-Hour serum insulin\n",
    "    5: Body mass index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6  148  72  35    0  33.6  0.627  50  1\n",
      "0   1   85  66  29    0  26.6  0.351  31  0\n",
      "1   8  183  64   0    0  23.3  0.672  32  1\n",
      "2   1   89  66  23   94  28.1  0.167  21  0\n",
      "3   0  137  40  35  168  43.1  2.288  33  1\n",
      "4   5  116  74   0    0  25.6  0.201  30  0\n",
      "5   3   78  50  32   88  31.0  0.248  26  1\n",
      "6  10  115   0   0    0  35.3  0.134  29  0\n",
      "7   2  197  70  45  543  30.5  0.158  53  1\n",
      "8   8  125  96   0    0   0.0  0.232  54  1\n",
      "9   4  110  92   0    0  37.6  0.191  30  0\n"
     ]
    }
   ],
   "source": [
    "## We can confirm the missing values, by analyzing the raw data. Therefore, we will print the first 10 rows of the dataset\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify things, we can print the count of the number of missing values on each column. \n",
    "For better visualization, we will mark all missing values as \"True\", and then, we can count the the \"True\" values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    111\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8    500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "## count the number of missing values from all 5 columns\n",
    "missing = (dataset[[0,1,2,3,4,5,6,7,8]] == 0).sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that columns 1, 2 and 5 has few missing value, while column 3, 4 and 8 have many missing values.\n",
    "In Python, missing values are usually marked as NaN. This values Nan are ignored when operations are performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    111\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8    500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan\n",
    "## replacing all zero values by nan in the dataset\n",
    "dataset[[0,1,2,3,4,5,6,7,8]] = dataset[[0,1,2,3,4,5,6,7,8]].replace(0,nan)\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the sum of counting the zeros in the dayaset, matches the counting when using nan, confirms that we marked and identified the missing values correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0      1     2     3      4     5      6   7    8\n",
      "0   6.0  148.0  72.0  35.0    NaN  33.6  0.627  50  1.0\n",
      "1   1.0   85.0  66.0  29.0    NaN  26.6  0.351  31  NaN\n",
      "2   8.0  183.0  64.0   NaN    NaN  23.3  0.672  32  1.0\n",
      "3   1.0   89.0  66.0  23.0   94.0  28.1  0.167  21  NaN\n",
      "4   NaN  137.0  40.0  35.0  168.0  43.1  2.288  33  1.0\n",
      "5   5.0  116.0  74.0   NaN    NaN  25.6  0.201  30  NaN\n",
      "6   3.0   78.0  50.0  32.0   88.0  31.0  0.248  26  1.0\n",
      "7  10.0  115.0   NaN   NaN    NaN  35.3  0.134  29  NaN\n",
      "8   2.0  197.0  70.0  45.0  543.0  30.5  0.158  53  1.0\n",
      "9   8.0  125.0  96.0   NaN    NaN   NaN  0.232  54  1.0\n"
     ]
    }
   ],
   "source": [
    "## confirming that the zero values were replaced by NaN\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having missing values in a training dataset can cause errors in the machine learning algorithms and lead to erroneous predictions.\n",
    "It is essential to handle the missing data prior to developing the model and the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the missing values\n",
    "The easiest and simplistic strategy to handle the missing data is to remove all records containing missing data.\n",
    "To achieve this, a new Panda DataFrame can be created with the rows containing the missing values removed.\n",
    "Pandas provide a function dropna(), that can be used to remove columns or rows with missing data. In our example, we will use this function to remove all wors that contain missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# summarize the shape of the raw data\n",
    "print(dataset.shape)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# drop rows with missing values\n",
    "dataset.dropna(inplace=True)\n",
    "# summarize the shape of the data with missing rows removed\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the code above:\n",
    "    - the first row shows the initial number of rows contained in the dataset\n",
    "    - the second row shows the remaining number of rows that do not contain missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data had been cleaned for missing values, an algorithm sensitive to missing data can be used to determine the accuracy that can be obtained with the remaining data. \n",
    "#### Latent Dirichlet Allocation (LDA) \n",
    "LDA is an unsupervised learning algorithm that views data as words and works on making a key assumption. [2]\n",
    "\n",
    "Running this algorithm, the output might vary, given the nature of the algorithm. The algorithm should be executed a few times in a row and compute the average outcome to determine the average accuracy that the data can provide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "# define the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach presented above, which implies the deletion of all rows containing missing values, can limit the model's prediction. Therefore, new methods of dealing with missing values will be detailed below.\n",
    "\n",
    "#### Impute Missing Values\n",
    "This method implies the replacement of missing values, and there are many ways of replacing missing values, such as:\n",
    "Replacing a missing value with:\n",
    "    1. a constant value that has meaning \n",
    "    2. a random value from another record\n",
    "    3. a mean, median or mode value for that column\n",
    "    4. a value estimated by another predictive value\n",
    "Each option presented above will have a different impact on the model, and on the predictions, the model will produce. \n",
    "Pandas, provide a function called fillna(), that replaces missing values with a specific value.\n",
    "##### Replacing missing values with the mean of the column.\n",
    "This function allows the developer to specify the value that replaces the missing value and the technique used to replace it.\n",
    "The Pipeline is used to define the modeling pipeline, where data is primarly passed through the SimpleImputer to be transformed,  and only after fed to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.762\n"
     ]
    }
   ],
   "source": [
    "# example of evaluating a model after an imputer transform\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# mark zero values as missing or NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "# define the imputer\n",
    "imputer = SimpleImputer(missing_values=nan, strategy='mean')\n",
    "# define the model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "# define the modeling pipeline\n",
    "pipeline = Pipeline(steps=[('imputer', imputer),('model', lda)])\n",
    "# define the cross validation procedure\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model\n",
    "result = cross_val_score(pipeline, X, y, cv=kfold, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the accuracy from the LDA algorithm that removes the rows with missing values and the accuracy of the model that replaced the missing values with the column's mean. We can observe that accuracy had decreased.\n",
    "Try replacing the missing values with other values and compare the results again. For a more detailed example of imputing missing values, check this tutorial: https://machinelearningmastery.com/statistical-imputation-for-missing-values-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "    1. Jason Brownlee, 2017, \"How to Handle Missing Data with Python\", Available at: https://machinelearningmastery.com/handle-missing-data-python/, (Accessed 10 December 2020)\n",
    "    \n",
    "    2. Tyler Doll, 2018, \"LDA Topic Modeling: An Explanation\" , Available at: https://towardsdatascience.com/lda-topic-modeling-an-explanation-e184c90aadcd, (Accessed 01.01.2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
